{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "notebook_start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1rKZelPMLlM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# this makes it so that the outputs of the predict methods have the id as a column\n",
    "# instead of as the index\n",
    "os.environ['NIXTLA_ID_AS_COL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJdRshVaMN73"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# df = pd.read_csv('/content/drive/My Drive/TCC/m6dataset.csv')\n",
    "df = pd.read_csv('m6dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ywgm0_RwNalm"
   },
   "outputs": [],
   "source": [
    "TEST_ROWS = 7\n",
    "\n",
    "# Splitting the dataframe into train and test sets\n",
    "train_df = df.iloc[:-TEST_ROWS]\n",
    "test_df = df.iloc[-TEST_ROWS:]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGhFhVZPNcUH"
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KJhkKS0NcIY"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRY0KieMNb6L"
   },
   "outputs": [],
   "source": [
    "# prompt: create a method for plotting df using an interactive line graph, one line for columns, starting from column 2, column 1 is the index, ignore column 0. the graph must show only the legend and value of the line where the mouse hovers over.\n",
    "import plotly.express as px\n",
    "\n",
    "def plot_df(df):\n",
    "  df = df.set_index(df.columns[0])\n",
    "  fig = px.line(df, x=df.index, y=df.columns[2:], hover_data={\"variable\":False})\n",
    "  fig.update_traces(mode='lines', hovertemplate=None)\n",
    "  # fig.update_layout(hovermode=\"x unified\")\n",
    "  fig.update_layout(\n",
    "      title='M6 Dataset',\n",
    "      xaxis_title='Days',\n",
    "      yaxis_title='Adj. Values',\n",
    "      hovermode='closest',  # Ensures that only the data point under the cursor is displayed\n",
    "      showlegend=True       # Display legend\n",
    "  )\n",
    "  fig.show()\n",
    "\n",
    "plot_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzKJtWWqNrrf"
   },
   "source": [
    "# NIXTLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UnzMOMkNbpB"
   },
   "outputs": [],
   "source": [
    "#!pip install neuralforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYiTvkufhna9"
   },
   "outputs": [],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from ray import tune\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKD9eczhlerV"
   },
   "outputs": [],
   "source": [
    "#torch.set_float32_matmul_precision('medium' | 'high' | 'highest')\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCTDxR2urivY"
   },
   "source": [
    "## Auto Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_tUcjr9Im7R"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6rGEYoFKmgr"
   },
   "outputs": [],
   "source": [
    "import neuralforecast.auto\n",
    "from neuralforecast.auto import AutoNHITS, AutoRNN, AutoLSTM, AutoGRU, AutoTCN, AutoDeepAR, AutoDilatedRNN, AutoBiTCN\n",
    "from neuralforecast.auto import AutoMLP, AutoNBEATS, AutoNBEATSx, AutoDLinear, AutoNLinear, AutoTiDE, AutoDeepNPTS\n",
    "from neuralforecast.auto import AutoTFT, AutoVanillaTransformer, AutoInformer, AutoAutoformer, AutoFEDformer\n",
    "from neuralforecast.auto import AutoPatchTST, AutoiTransformer, AutoTimesNet\n",
    "\n",
    "horizont = 1\n",
    "\n",
    "# --- CONFIGS ---\n",
    "\n",
    "# Extract the default hyperparameter settings\n",
    "\n",
    "#A. RNN-Based\n",
    "rnn_config = AutoRNN.get_default_config(h = horizont, backend=\"ray\")\n",
    "lstm_config = AutoLSTM.get_default_config(h = horizont, backend=\"ray\")\n",
    "gru_config = AutoGRU.get_default_config(h = horizont, backend=\"ray\")\n",
    "tcn_config = AutoTCN.get_default_config(h = horizont, backend=\"ray\")\n",
    "deep_ar_config = AutoDeepAR.get_default_config(h = horizont, backend=\"ray\")\n",
    "dilated_rnn_config = AutoDilatedRNN.get_default_config(h = horizont, backend=\"ray\")\n",
    "bitcn_config = AutoBiTCN.get_default_config(h = horizont, backend=\"ray\")\n",
    "\n",
    "#B. MLP-Based\n",
    "mlp_config = AutoMLP.get_default_config(h = horizont, backend=\"ray\")\n",
    "nbeats_config = AutoNBEATS.get_default_config(h = horizont, backend=\"ray\")\n",
    "nbeatsx_config = AutoNBEATSx.get_default_config(h = horizont, backend=\"ray\")\n",
    "nhits_config = AutoNHITS.get_default_config(h = horizont, backend=\"ray\")\n",
    "dlinear_config = AutoDLinear.get_default_config(h = horizont, backend=\"ray\")\n",
    "nlinear_config = AutoNLinear.get_default_config(h = horizont, backend=\"ray\")\n",
    "tide_config = AutoTiDE.get_default_config(h = horizont, backend=\"ray\")\n",
    "deep_npts_config = AutoDeepNPTS.get_default_config(h = horizont, backend=\"ray\")\n",
    "\n",
    "#C. Transformer models\n",
    "tft_config = AutoTFT.get_default_config(h = horizont, backend=\"ray\")\n",
    "vanilla_config = AutoVanillaTransformer.get_default_config(h = horizont, backend=\"ray\")\n",
    "informer_config = AutoInformer.get_default_config(h = horizont, backend=\"ray\")\n",
    "autoformer_config = AutoAutoformer.get_default_config(h = horizont, backend=\"ray\")\n",
    "fedformer_config = AutoFEDformer.get_default_config(h = horizont, backend=\"ray\")\n",
    "patch_tst_config = AutoPatchTST.get_default_config(h = horizont, backend=\"ray\")\n",
    "\n",
    "itransformer_config = AutoiTransformer.get_default_config(h = horizont, n_series=1, backend=\"ray\")\n",
    "\n",
    "#D. CNN Based\n",
    "timesnet_config = AutoTimesNet.get_default_config(h = horizont, backend=\"ray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fn4nhUGQljuk"
   },
   "outputs": [],
   "source": [
    "# --- MODELS ---\n",
    "#A. RNN-Based\n",
    "rnn_model = AutoRNN(h=horizont, config=rnn_config)\n",
    "lstm_model = AutoLSTM(h=horizont, config=lstm_config)\n",
    "gru_model = AutoGRU(h=horizont, config=gru_config)\n",
    "tcn_model = AutoTCN(h=horizont, config=tcn_config)\n",
    "deep_ar_model = AutoDeepAR(h=horizont, config=deep_ar_config)\n",
    "dilated_rnn_model = AutoDilatedRNN(h=horizont, config=dilated_rnn_config)\n",
    "bitcn_model = AutoBiTCN(h=horizont, config=bitcn_config)\n",
    "\n",
    "#B. MLP-Based\n",
    "mlp_model = AutoMLP(h=horizont, config=mlp_config)\n",
    "nbeats_model = AutoNBEATS(h=horizont, config=nbeats_config)\n",
    "nbeatsx_model = AutoNBEATSx(h=horizont, config=nbeats_config)\n",
    "nhits_model = AutoNHITS(h=horizont, config=nhits_config)\n",
    "dlinear_model = AutoDLinear(h=horizont, config=dlinear_config)\n",
    "nlinear_model = AutoNLinear(h=horizont, config=nlinear_config)\n",
    "tide_model = AutoTiDE(h=horizont, config=tide_config)\n",
    "deep_npts_model = AutoDeepNPTS(h=horizont, config=deep_npts_config)\n",
    "\n",
    "#C. Transformer models\n",
    "tft_model = AutoTFT(h=horizont, config=tft_config)\n",
    "vanilla_model = AutoVanillaTransformer(h=horizont, config=vanilla_config)\n",
    "informer_model = AutoInformer(h=horizont, config=informer_config)\n",
    "autoformer_model = AutoAutoformer(h=horizont, config=autoformer_config)\n",
    "fedformer_model = AutoFEDformer(h=horizont, config=fedformer_config)\n",
    "patch_tst_model = AutoPatchTST(h=horizont, config=patch_tst_config)\n",
    "\n",
    "itransformer_model = AutoiTransformer(h=horizont, n_series=1, config=itransformer_config)\n",
    "\n",
    "#D. CNN Based\n",
    "timesnet_model = AutoTimesNet(h=horizont, config=timesnet_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "  'lstm': lstm_model,\n",
    "  'mlp': mlp_model,\n",
    "  'dlinear': dlinear_model,\n",
    "  'nlinear': nlinear_model,\n",
    "  'informer': informer_model,\n",
    "  'autoformer': autoformer_model,\n",
    "  'fedformer': fedformer_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JovrCqUtI3IX"
   },
   "outputs": [],
   "source": [
    "model_name = 'CHANGEME!!!!!!!'\n",
    "frequency = 'D' # 'B' business day frequency (https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)\n",
    "\n",
    "models = [\n",
    "    MODELS[model_name]\n",
    "    #rnn_model,\n",
    "    #lstm_model,  # ......... 1\n",
    "    #gru_model,\n",
    "    #tcn_model,\n",
    "    #deep_ar_model,\n",
    "    #dilated_rnn_model,\n",
    "    #bitcn_model,\n",
    "    #mlp_model,  # .......... 2\n",
    "    #nbeats_model,\n",
    "    #nbeatsx_model,\n",
    "    #nhits_model,\n",
    "    #dlinear_model,  # ...... 3\n",
    "    #nlinear_model,  # ...... 4\n",
    "    #tide_model,\n",
    "    #deep_npts_model,\n",
    "    #tft_model,\n",
    "    #vanilla_model,\n",
    "    #informer_model,  # ..... 5\n",
    "    #autoformer_model,  # ... 6\n",
    "    #fedformer_model,  # .... 7\n",
    "    #patch_tst_model,\n",
    "    #itransformer_model,\n",
    "    #timesnet_model\n",
    "    ]\n",
    "nf = NeuralForecast(\n",
    "      models=models,\n",
    "      freq=frequency\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4yBcy__Os5F"
   },
   "outputs": [],
   "source": [
    "def convert_nixtla(df):\n",
    "  ndf = pd.DataFrame(columns=['unique_id', 'ds', 'y'])\n",
    "\n",
    "  for col in df.columns[1:]:\n",
    "    temp = df[['Date', col]].copy()\n",
    "    temp['unique_id'] = col\n",
    "    temp.rename(columns={'Date':'ds', col: 'y'}, inplace=True)\n",
    "    ndf = pd.concat([ndf, temp], ignore_index=True)\n",
    "  ndf['ds']=pd.to_datetime(ndf['ds'])\n",
    "\n",
    "  return ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6odzr4xRuNZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(0, TEST_ROWS):\n",
    "  print('--- FORECASTING ' + str(i+1) + ' ---')\n",
    "\n",
    "  ndf=convert_nixtla(train_df)\n",
    "  nf.fit(df=ndf)\n",
    "  pred = nf.predict()\n",
    "\n",
    "  # transposing the prediction and adjustin columns\n",
    "  date_value = pd.to_datetime(pred['ds'].iloc[0]).strftime('%Y-%m-%d')\n",
    "  pred.set_index('unique_id', inplace=True)\n",
    "  predt = pred.drop(columns=['ds']).T\n",
    "  predt.insert(0, 'Date', date_value)\n",
    "  try:\n",
    "      preds = pd.concat([preds, predt])\n",
    "  except NameError:\n",
    "      preds = predt\n",
    "\n",
    "  # prompt: concat row i from test_df at the end of train_df\n",
    "  train_df = pd.concat([train_df, test_df.iloc[[i]]])\n",
    "\n",
    "stop_time = datetime.now()\n",
    "elapsed_time = stop_time - start_time\n",
    "\n",
    "print(f\"Cell started at: {start_time}\")\n",
    "print(f\"Cell stopped at: {stop_time}\")\n",
    "print(f\"Elapsed time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qykfIFbLV8K"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"file_example_MP3_1MG.mp3\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prompt: plot columns 1 from test_df and preds, the title is the column name\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_pred_vs_test(test_df, preds):\n",
    "  for col in test_df.columns[1:]:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=test_df['Date'], y=test_df[col], mode='lines', name='Test'))\n",
    "    fig.add_trace(go.Scatter(x=preds['Date'], y=preds[col], mode='lines', name='Predictions'))\n",
    "    fig.update_layout(title=col, xaxis_title='Date', yaxis_title='Value')\n",
    "    fig.show()\n",
    "\n",
    "plot_pred_vs_test(test_df, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: compare test_df and preds columns MAE, RSME and POCID, put results in a pandas dataframe\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def pocid(actual, forecast):\n",
    "  actual = np.array(actual)\n",
    "  forecast = np.array(forecast)\n",
    "  sum_abs_diff = np.sum(np.abs(actual - forecast))\n",
    "  sum_actual = np.sum(actual)\n",
    "  return (sum_abs_diff / sum_actual) * 100\n",
    "\n",
    "results = []\n",
    "for col in test_df.columns[1:]:\n",
    "  mae = mean_absolute_error(test_df[col], preds[col])\n",
    "  rmse = np.sqrt(mean_squared_error(test_df[col], preds[col]))\n",
    "  pocid_val = pocid(test_df[col], preds[col])\n",
    "  results.append([col, mae, rmse, pocid_val])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Column', 'MAE', 'RMSE', 'POCID'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_stop = datetime.now()\n",
    "\n",
    "print(f\"Notebook started at: {notebook_start}\")\n",
    "print(f\"Notebook stopped at: {notebook_stop}\")\n",
    "\n",
    "exec_df = pd.DataFrame({\n",
    "  'Model': [model_name],\n",
    "  'Cell Start': [start_time],\n",
    "  'Cell Stop': [stop_time],\n",
    "  'Cell Elapsed': [elapsed_time],\n",
    "  'Note Start': [notebook_start],\n",
    "  'Note Stop': [notebook_stop]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: save results_df into the TCC drive named autoarima.csv\n",
    "preds.to_csv('./results/' + model_name + '-with_update-pred.csv', index=False)\n",
    "test_df.to_csv('./results/' + model_name + '-with_update-val.csv', index=False)\n",
    "results_df.to_csv('./results/' + model_name + '-with_update-metrics.csv', index=False)\n",
    "exec_df.to_csv('./results/' + model_name + '-with_update-exec_time.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:neuralforecast] *",
   "language": "python",
   "name": "conda-env-neuralforecast-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
